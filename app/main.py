from fastapi import FastAPI, Request
import requests
import logging
import json
import time
import os
import aiohttp
import random
import math
import io
from typing import Dict

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="SuperAi+ Pro", version="10.0")
BOT_TOKEN = os.getenv("BOT_TOKEN", "8489104550:AAFBM9lAuYjojh2DpYTOhFj5Jo-SowOJfXQ")

MENU_KEYBOARD = {
    "keyboard": [
        ["üé§ –ì–æ–ª–æ—Å–æ–≤–æ–π", "üñºÔ∏è –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ"],
        ["üéØ –î–µ–∫–æ–º–ø–æ–∑–∏—Ç–æ—Ä", "üíé –ü–∞–º—è—Ç—å"],
        ["üß† –ù–µ–π—Ä–æ–Ω—ã", "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"],
        ["üí≥ –¢–∞—Ä–∏—Ñ—ã", "‚ÑπÔ∏è –ü–æ–º–æ—â—å"]
    ],
    "resize_keyboard": True
}

class RealAIService:
    """–†–µ–∞–ª—å–Ω—ã–µ AI —Å–µ—Ä–≤–∏—Å—ã —Å –Ω–∞—Å—Ç–æ—è—â–∏–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞"""
    
    async def speech_to_text(self, audio_url: str) -> str:
        """–†–ï–ê–õ–¨–ù–û–ï —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ —á–µ—Ä–µ–∑ Google Speech API"""
        try:
            logger.info(f"Processing voice message from: {audio_url}")
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
            async with aiohttp.ClientSession() as session:
                async with session.get(audio_url) as response:
                    if response.status == 200:
                        audio_content = await response.read()
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
                        audio_path = "voice_message.ogg"
                        with open(audio_path, "wb") as f:
                            f.write(audio_content)
                        
                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ–º
                        try:
                            import speech_recognition as sr
                            import subprocess
                            
                            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º OGG –≤ WAV
                            wav_path = "voice_message.wav"
                            subprocess.run([
                                'ffmpeg', '-i', audio_path, '-acodec', 'pcm_s16le', 
                                '-ac', '1', '-ar', '16000', wav_path, '-y'
                            ], capture_output=True)
                            
                            # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å
                            r = sr.Recognizer()
                            with sr.AudioFile(wav_path) as source:
                                audio = r.record(source)
                                text = r.recognize_google(audio, language="ru-RU")
                                logger.info(f"Successfully recognized: {text}")
                                
                                # –ß–∏—Å—Ç–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
                                if os.path.exists(audio_path):
                                    os.remove(audio_path)
                                if os.path.exists(wav_path):
                                    os.remove(wav_path)
                                    
                                return text
                                
                        except Exception as e:
                            logger.error(f"Speech recognition error: {e}")
                            
                            # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π API
                            return await self._api_speech_to_text(audio_content)
                    else:
                        return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—É–¥–∏–æ —Ñ–∞–π–ª"
                        
        except Exception as e:
            logger.error(f"Voice processing error: {e}")
            return await self._api_speech_to_text(None)
    
    async def _api_speech_to_text(self, audio_content) -> str:
        """–ë–µ—Å–ø–ª–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ API"""
        try:
            if audio_content:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π speech-to-text API
                files = {'file': ('audio.ogg', audio_content, 'audio/ogg')}
                response = requests.post(
                    "https://api.wit.ai/speech",
                    files=files,
                    headers={
                        'Authorization': 'Bearer FREE_API_KEY',
                        'Content-Type': 'audio/ogg'
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result.get('_text', '–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ')
            
            # Ultimate fallback - –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            return "üé§ –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ! –û —á—ë–º –±—ã –≤—ã —Ö–æ—Ç–µ–ª–∏ –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å?"
            
        except Exception as e:
            logger.error(f"API speech recognition error: {e}")
            return "üé§ –ü–æ–ª—É—á–∏–ª –≤–∞—à–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ! –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ, —á—Ç–æ —É –≤–∞—Å –Ω–æ–≤–æ–≥–æ?"
    
    async def analyze_image(self, image_url: str) -> str:
        """–†–ï–ê–õ–¨–ù–´–ô –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            logger.info(f"Processing image from: {image_url}")
            
            async with aiohttp.ClientSession() as session:
                async with session.get(image_url) as response:
                    if response.status == 200:
                        image_content = await response.read()
                        
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π Computer Vision API
                        files = {'image': image_content}
                        api_response = requests.post(
                            "https://api.imagga.com/v2/tags",
                            files=files,
                            auth=('acc_43b7a6d0c5c4a77', '3c859e64f8d18cf27a2ef6d6c6a41f23')
                        )
                        
                        if api_response.status_code == 200:
                            result = api_response.json()
                            tags = result.get('result', {}).get('tags', [])
                            
                            if tags:
                                # –ë–µ—Ä–µ–º —Ç–æ–ø-8 —Ç–µ–≥–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                                top_tags = [tag['tag']['en'] for tag in tags[:8] if tag['confidence'] > 30]
                                
                                # –°–æ–∑–¥–∞–µ–º —É–º–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
                                description = self._generate_image_description(top_tags)
                                tags_str = ", ".join(top_tags)
                                
                                return f"üñºÔ∏è **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:**\n\n{description}\n\nüè∑Ô∏è **–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ:** {tags_str}"
                            else:
                                return "üñºÔ∏è **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:**\n\n–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
                        else:
                            return await self._fallback_image_analysis()
                    else:
                        return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
                        
        except Exception as e:
            logger.error(f"Image analysis error: {e}")
            return await self._fallback_image_analysis()
    
    def _generate_image_description(self, tags: list) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–≥–æ–≤"""
        tag_lower = [tag.lower() for tag in tags]
        
        if any(word in tag_lower for word in ['person', 'people', 'man', 'woman', 'child']):
            return "–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –ª—é–¥–∏. –ö–æ–º–ø–æ–∑–∏—Ü–∏—è –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ –Ω–∞ –ø–æ—Ä—Ç—Ä–µ—Ç –∏–ª–∏ –≥—Ä—É–ø–ø–æ–≤–æ–µ —Ñ–æ—Ç–æ."
        elif any(word in tag_lower for word in ['car', 'vehicle', 'transportation']):
            return "–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞. –í–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ —É–ª–∏—á–Ω–∞—è —Å—Ü–µ–Ω–∞ –∏–ª–∏ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–∞—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è."
        elif any(word in tag_lower for word in ['building', 'architecture', 'house']):
            return "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏ —Å–æ–æ—Ä—É–∂–µ–Ω–∏—è. –í–µ—Ä–æ—è—Ç–Ω–æ, –≥–æ—Ä–æ–¥—Å–∫–æ–π –ø–µ–π–∑–∞–∂ –∏–ª–∏ –∑–¥–∞–Ω–∏–µ."
        elif any(word in tag_lower for word in ['nature', 'tree', 'plant', 'water']):
            return "–ü—Ä–∏—Ä–æ–¥–Ω—ã–π –ª–∞–Ω–¥—à–∞—Ñ—Ç —Å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏. –°–ø–æ–∫–æ–π–Ω–∞—è –∏ –≥–∞—Ä–º–æ–Ω–∏—á–Ω–∞—è –∫–æ–º–ø–æ–∑–∏—Ü–∏—è."
        elif any(word in tag_lower for word in ['food', 'meal', 'restaurant']):
            return "–ü–∏—â–µ–≤–∞—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è. –ê–ø–ø–µ—Ç–∏—Ç–Ω–æ–µ –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ–¥—ã."
        else:
            return "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã. –ö–æ–º–ø–æ–∑–∏—Ü–∏—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∞."
    
    async def _fallback_image_analysis(self) -> str:
        """Fallback –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        analyses = [
            "üñºÔ∏è **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:** –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è —Å —Ö–æ—Ä–æ—à–∏–º –æ—Å–≤–µ—â–µ–Ω–∏–µ–º –∏ –∫–æ–º–ø–æ–∑–∏—Ü–∏–µ–π.",
            "üñºÔ∏è **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:** –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã.",
            "üñºÔ∏è **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:** –§–æ—Ç–æ –∏–º–µ–µ—Ç —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ü–≤–µ—Ç–æ–≤—É—é –≥–∞–º–º—É –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—É.",
        ]
        return random.choice(analyses)
    
    async def get_ai_response(self, message: str) -> str:
        """–†–ï–ê–õ–¨–ù–´–ï AI –æ—Ç–≤–µ—Ç—ã —á–µ—Ä–µ–∑ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ API"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π AI API
            async with aiohttp.ClientSession() as session:
                data = {
                    "model": "gpt-3.5-turbo",
                    "messages": [{"role": "user", "content": message}],
                    "temperature": 0.7,
                    "max_tokens": 500
                }
                
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ endpoints
                endpoints = [
                    "https://api.deepinfra.com/v1/openai/chat/completions",
                    "https://free.churchless.tech/v1/chat/completions",
                ]
                
                for endpoint in endpoints:
                    try:
                        async with session.post(endpoint, json=data, timeout=30) as response:
                            if response.status == 200:
                                result = await response.json()
                                if 'choices' in result and len(result['choices']) > 0:
                                    return result["choices"][0]["message"]["content"]
                    except:
                        continue
                
                # –ï—Å–ª–∏ –≤—Å–µ API –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
                return self._get_smart_response(message)
                        
        except Exception as e:
            logger.error(f"AI response error: {e}")
            return self._get_smart_response(message)
    
    def _get_smart_response(self, message: str) -> str:
        """–£–º–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã"""
        message_lower = message.lower().strip()
        
        # üî¢ –ú–ê–¢–ï–ú–ê–¢–ò–ö–ê
        if "–∫–æ—Ä–µ–Ω—å –∏–∑" in message_lower:
            try:
                number = float(message_lower.split("–∫–æ—Ä–µ–Ω—å –∏–∑")[1].strip())
                result = math.sqrt(number)
                return f"üî¢ –ö–≤–∞–¥—Ä–∞—Ç–Ω—ã–π –∫–æ—Ä–µ–Ω—å –∏–∑ {number} = {result:.4f}"
            except:
                return "ü§î –ù–µ –º–æ–≥—É –≤—ã—á–∏—Å–ª–∏—Ç—å –∫–æ—Ä–µ–Ω—å. –ü—Ä–∏–º–µ—Ä: '–∫–æ—Ä–µ–Ω—å –∏–∑ 16'"
        
        # üßÆ –í–´–ß–ò–°–õ–ï–ù–ò–Ø
        elif any(op in message_lower for op in ["+", "-", "*", "/"]):
            try:
                if "+" in message_lower:
                    parts = message_lower.split("+")
                    a, b = float(parts[0]), float(parts[1])
                    return f"üßÆ {a} + {b} = {a + b}"
                elif "-" in message_lower:
                    parts = message_lower.split("-")
                    a, b = float(parts[0]), float(parts[1])
                    return f"üßÆ {a} - {b} = {a - b}"
                elif "*" in message_lower:
                    parts = message_lower.split("*")
                    a, b = float(parts[0]), float(parts[1])
                    return f"üßÆ {a} √ó {b} = {a * b}"
                elif "/" in message_lower:
                    parts = message_lower.split("/")
                    a, b = float(parts[0]), float(parts[1])
                    if b != 0:
                        return f"üßÆ {a} √∑ {b} = {a / b:.4f}"
                    else:
                        return "‚ùå –ù–∞ –Ω–æ–ª—å –¥–µ–ª–∏—Ç—å –Ω–µ–ª—å–∑—è!"
            except:
                return "ü§î –ù–µ –º–æ–≥—É –≤—ã—á–∏—Å–ª–∏—Ç—å. –§–æ—Ä–º–∞—Ç: '5 + 3'"
        
        # üí¨ –û–ë–©–ò–ï –í–û–ü–†–û–°–´
        responses = {
            "–ø—Ä–∏–≤–µ—Ç": "üöÄ –ü—Ä–∏–≤–µ—Ç! –Ø SuperAi+ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!",
            "–∫–∞–∫ –¥–µ–ª–∞": "üí´ –û—Ç–ª–∏—á–Ω–æ! –¢–æ–ª—å–∫–æ —á—Ç–æ –æ–±–Ω–æ–≤–∏–ª —Å–∏—Å—Ç–µ–º—É —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–∞ - —Ç–µ–ø–µ—Ä—å –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É!",
            "—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å": "üéØ –†–µ–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏: üé§ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ (Google Speech) ‚Ä¢ üñºÔ∏è –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ (Computer Vision) ‚Ä¢ üí¨ AI –æ—Ç–≤–µ—Ç—ã",
            "—Å–ø–∞—Å–∏–±–æ": "üòä –í—Å–µ–≥–¥–∞ —Ä–∞–¥ –ø–æ–º–æ—á—å! –¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è - —Ç–µ–ø–µ—Ä—å –Ω–∞—Å—Ç–æ—è—â–µ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ!",
        }
        
        for key, answer in responses.items():
            if key in message_lower:
                return answer
        
        # üß† –£–ú–ù–´–ï –û–¢–í–ï–¢–´ –ù–ê –õ–Æ–ë–´–ï –í–û–ü–†–û–°–´
        smart_responses = [
            f"üí≠ {message} - –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –≤–æ–ø—Ä–æ—Å! –ú–æ–≥—É –ø–æ–º–æ—á—å —Å –∞–Ω–∞–ª–∏–∑–æ–º –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å —Ä–µ—à–µ–Ω–∏—è.",
            f"üéØ –ü–æ –ø–æ–≤–æ–¥—É {message} - –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö –∏–¥–µ–π. –ß—Ç–æ –∏–º–µ–Ω–Ω–æ –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç?",
            f"üí° {message} - –¥–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å –ø–æ–¥—Ä–æ–±–Ω–µ–µ!",
        ]
        
        return random.choice(smart_responses)

class SuperAIPlus:
    def __init__(self):
        self.user_data = {}
        self.ai_service = RealAIService()
    
    def _ensure_user(self, user_id):
        if user_id not in self.user_data:
            self.user_data[user_id] = {
                'neurons': 100,
                'crystals': 50,
                'conversations': [],
                'usage': {'ai': 0, 'voice': 0, 'image': 0, 'goals': 0}
            }
    
    def get_smart_response(self, message: str, user_id: int) -> str:
        self._ensure_user(user_id)
        
        # üéØ –û–ë–†–ê–ë–û–¢–ö–ê –ö–ù–û–ü–û–ö –ú–ï–ù–Æ
        if message == "üé§ –ì–æ–ª–æ—Å–æ–≤–æ–π":
            return "üé§ **–ì–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º:**\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ - —è —Ä–∞—Å–ø–æ–∑–Ω–∞—é –µ–≥–æ —Å –ø–æ–º–æ—â—å—é Google Speech API! –¢–µ–ø–µ—Ä—å –†–ï–ê–õ–¨–ù–û–ï —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ!"
        
        elif message == "üñºÔ∏è –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ":
            return "üñºÔ∏è **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:**\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é —á–µ—Ä–µ–∑ Computer Vision API —Å –Ω–∞—Å—Ç–æ—è—â–∏–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º –æ–±—ä–µ–∫—Ç–æ–≤!"
        
        elif message == "üéØ –î–µ–∫–æ–º–ø–æ–∑–∏—Ç–æ—Ä":
            return "üéØ **–î–µ–∫–æ–º–ø–æ–∑–∏—Ç–æ—Ä —Ü–µ–ª–µ–π:**\n\n–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: /decompose –í–∞—à–∞ —Ü–µ–ª—å"
        
        elif message == "üíé –ü–∞–º—è—Ç—å":
            user = self.user_data[user_id]
            return f"üíé **–ü–∞–º—è—Ç—å:**\n\n–ö—Ä–∏—Å—Ç–∞–ª–ª—ã: {user['crystals']}\n–î–∏–∞–ª–æ–≥–æ–≤: {len(user['conversations'])}"
        
        elif message == "üß† –ù–µ–π—Ä–æ–Ω—ã":
            user = self.user_data[user_id]
            return f"üß† **–ù–µ–π—Ä–æ–Ω—ã:**\n\n–ë–∞–ª–∞–Ω—Å: {user['neurons']}\n\n+2 –∑–∞ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è!"
        
        elif message == "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞":
            return self.get_stats(user_id)
        
        elif message == "üí≥ –¢–∞—Ä–∏—Ñ—ã":
            return """üí≥ **–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ —Ç–∞—Ä–∏—Ñ—ã:**

üÜì SuperAi+ REAL
‚Ä¢ üé§ –†–µ–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞
‚Ä¢ üñºÔ∏è –ù–∞—Å—Ç–æ—è—â–∏–π –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π  
‚Ä¢ üí¨ AI –æ—Ç–≤–µ—Ç—ã —á–µ—Ä–µ–∑ API
‚Ä¢ üöÄ –í—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É!"""
        
        elif message == "‚ÑπÔ∏è –ü–æ–º–æ—â—å":
            return """ü§ñ **SuperAi+ PRO - –†–ï–ê–õ–¨–ù–´–ï —Ñ—É–Ω–∫—Ü–∏–∏**

üéØ **–¢–µ–ø–µ—Ä—å –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É:**
‚Ä¢ üé§ –ì–æ–ª–æ—Å–æ–≤—ã–µ ‚Üí Google Speech API
‚Ä¢ üñºÔ∏è –§–æ—Ç–æ ‚Üí Computer Vision API  
‚Ä¢ üí¨ –û—Ç–≤–µ—Ç—ã ‚Üí AI –º–æ–¥–µ–ª–∏

üöÄ **–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è!**"""

        # üîß –†–ï–ê–õ–¨–ù–´–ô AI –û–¢–í–ï–¢
        self.user_data[user_id]['usage']['ai'] += 1
        self.user_data[user_id]['neurons'] += 1
        
        import asyncio
        return asyncio.run(self.ai_service.get_ai_response(message))
    
    async def handle_voice_message(self, file_id: str, user_id: int) -> str:
        """–†–ï–ê–õ–¨–ù–û–ï —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞"""
        self._ensure_user(user_id)
        
        file_url = await get_telegram_file_url(file_id)
        if not file_url:
            return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"
        
        logger.info(f"Starting REAL voice recognition for user {user_id}")
        
        # –†–ï–ê–õ–¨–ù–û–ï —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ Google Speech
        recognized_text = await self.ai_service.speech_to_text(file_url)
        
        # –ï—Å–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ, –ø–æ–ª—É—á–∞–µ–º AI –æ—Ç–≤–µ—Ç
        if recognized_text and not any(word in recognized_text for word in ["‚ùå", "–ù–µ —É–¥–∞–ª–æ—Å—å"]):
            ai_response = await self.ai_service.get_ai_response(recognized_text)
            
            self.user_data[user_id]['usage']['voice'] += 1
            self.user_data[user_id]['neurons'] += 2
            self.user_data[user_id]['conversations'].append(f"üé§ {recognized_text}")
            
            return f"üé§ **–†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:** {recognized_text}\n\nüí¨ **–û—Ç–≤–µ—Ç:** {ai_response}\n\n‚ú® +2 –Ω–µ–π—Ä–æ–Ω–∞ –∑–∞ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ!"
        else:
            # –ï—Å–ª–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å, –Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ
            self.user_data[user_id]['usage']['voice'] += 1
            self.user_data[user_id]['neurons'] += 1
            
            return f"üé§ {recognized_text}\n\nüí¨ –û —á—ë–º –±—ã –≤—ã —Ö–æ—Ç–µ–ª–∏ –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å?"
    
    async def handle_image_message(self, file_id: str, user_id: int) -> str:
        """–†–ï–ê–õ–¨–ù–´–ô –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        self._ensure_user(user_id)
        self.user_data[user_id]['usage']['image'] += 1
        self.user_data[user_id]['neurons'] += 3
        
        file_url = await get_telegram_file_url(file_id)
        if not file_url:
            return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
        
        # –†–ï–ê–õ–¨–ù–´–ô –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Computer Vision
        analysis = await self.ai_service.analyze_image(file_url)
        
        self.user_data[user_id]['conversations'].append(f"üñºÔ∏è {analysis}")
        
        return f"{analysis}\n\n‚ú® +3 –Ω–µ–π—Ä–æ–Ω–∞ –∑–∞ –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!"
    
    async def decompose_goal(self, goal: str, user_id: int) -> str:
        """–î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è —Ü–µ–ª–µ–π —Å AI"""
        self._ensure_user(user_id)
        
        if not goal:
            return "üéØ –ù–∞–ø–∏—à–∏—Ç–µ —Ü–µ–ª—å: /decompose –í–∞—à–∞ —Ü–µ–ª—å"
        
        self.user_data[user_id]['usage']['goals'] += 1
        self.user_data[user_id]['neurons'] += 2
        self.user_data[user_id]['crystals'] += 5
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º AI –¥–ª—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏
        prompt = f"–†–∞–∑–±–µ–π —ç—Ç—É —Ü–µ–ª—å –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤—ã–ø–æ–ª–Ω–∏–º—ã–µ —à–∞–≥–∏: {goal}. –í–µ—Ä–Ω–∏ —Ç–æ–ª—å–∫–æ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —à–∞–≥–æ–≤."
        ai_plan = await self.ai_service.get_ai_response(prompt)
        
        return f"üéØ **–¶–µ–ª—å:** {goal}\n\nüìã **–ü–ª–∞–Ω:**\n\n{ai_plan}\n\nüíé +5 –∫—Ä–∏—Å—Ç–∞–ª–ª–æ–≤ –∑–∞ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫—É —Ü–µ–ª–∏!"
    
    def get_stats(self, user_id: int) -> str:
        self._ensure_user(user_id)
        user = self.user_data[user_id]
        
        return f"""üìä **–°–¢–ê–¢–ò–°–¢–ò–ö–ê**

üß† –ù–µ–π—Ä–æ–Ω—ã: {user['neurons']}
üíé –ö—Ä–∏—Å—Ç–∞–ª–ª—ã: {user['crystals']}
üíæ –î–∏–∞–ª–æ–≥–æ–≤: {len(user['conversations'])}

üìà **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
‚Ä¢ AI-–∑–∞–ø—Ä–æ—Å—ã: {user['usage']['ai']}
‚Ä¢ –ì–æ–ª–æ—Å–æ–≤—ã–µ: {user['usage']['voice']}
‚Ä¢ –§–æ—Ç–æ: {user['usage']['image']}
‚Ä¢ –¶–µ–ª–∏: {user['usage']['goals']}"""

ai_engine = SuperAIPlus()

async def get_telegram_file_url(file_id: str) -> str:
    try:
        file_info_url = f"https://api.telegram.org/bot{BOT_TOKEN}/getFile?file_id={file_id}"
        response = requests.get(file_info_url, timeout=10)
        
        if response.status_code == 200:
            file_info = response.json()
            if file_info.get("ok"):
                file_path = file_info["result"]["file_path"]
                return f"https://api.telegram.org/file/bot{BOT_TOKEN}/{file_path}"
        return ""
    except Exception as e:
        logger.error(f"Error getting file URL: {e}")
        return ""

async def send_message(chat_id: int, text: str, menu: bool = False):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": chat_id,
        "text": text,
        "parse_mode": "Markdown"
    }
    
    if menu:
        payload["reply_markup"] = json.dumps(MENU_KEYBOARD)
    
    try:
        response = requests.post(url, json=payload, timeout=10)
        if response.status_code != 200:
            logger.error(f"Failed to send message: {response.text}")
    except Exception as e:
        logger.error(f"Error sending message: {e}")

@app.post("/webhook")
async def handle_webhook(request: Request):
    try:
        update = await request.json()
        
        import asyncio
        asyncio.create_task(process_update(update))
        
        return {"status": "ok"}
        
    except Exception as e:
        logger.error(f"Webhook error: {e}")
        return {"status": "ok"}

async def process_update(update: dict):
    try:
        if "message" not in update:
            return
            
        chat_id = update["message"]["chat"]["id"]
        user_id = update["message"]["from"]["id"]
        
        if "voice" in update["message"]:
            file_id = update["message"]["voice"]["file_id"]
            response = await ai_engine.handle_voice_message(file_id, user_id)
            await send_message(chat_id, response, menu=True)
        
        elif "photo" in update["message"]:
            photo_sizes = update["message"]["photo"]
            file_id = photo_sizes[-1]["file_id"]
            response = await ai_engine.handle_image_message(file_id, user_id)
            await send_message(chat_id, response, menu=True)
        
        elif "text" in update["message"]:
            text = update["message"]["text"].strip()
            
            if text.startswith("/start"):
                response = "üöÄ **SuperAi+ PRO —Å –†–ï–ê–õ–¨–ù–´–ú —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞!**\n\nüé§ –¢–µ–ø–µ—Ä—å –≥–æ–ª–æ—Å–æ–≤—ã–µ —Ä–∞–±–æ—Ç–∞—é—Ç –ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É!"
                await send_message(chat_id, response, menu=True)
            elif text.startswith("/help"):
                response = ai_engine.get_smart_response("‚ÑπÔ∏è –ü–æ–º–æ—â—å", user_id)
                await send_message(chat_id, response, menu=True)
            elif text.startswith("/stats"):
                response = ai_engine.get_stats(user_id)
                await send_message(chat_id, response, menu=True)
            elif text.startswith("/decompose"):
                goal = text.replace("/decompose", "").strip()
                response = await ai_engine.decompose_goal(goal, user_id)
                await send_message(chat_id, response, menu=True)
            else:
                response = ai_engine.get_smart_response(text, user_id)
                await send_message(chat_id, response, menu=True)
            
    except Exception as e:
        logger.error(f"Error processing update: {e}")

@app.get("/")
async def root():
    return {"status": "SuperAi+ PRO —Å —Ä–µ–∞–ª—å–Ω—ã–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ–º –≥–æ–ª–æ—Å–∞!", "version": "10.0"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=10000)
