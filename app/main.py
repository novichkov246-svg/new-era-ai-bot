from fastapi import FastAPI, Request
import requests
import logging
import json
import time
import os
import aiohttp
import random
import math
from typing import Dict

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="SuperAi+ Pro", version="11.0")
BOT_TOKEN = os.getenv("BOT_TOKEN", "8489104550:AAFBM9lAuYjojh2DpYTOhFj5Jo-SowOJfXQ")

MENU_KEYBOARD = {
    "keyboard": [
        ["üé§ –ì–æ–ª–æ—Å–æ–≤–æ–π", "üñºÔ∏è –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ"],
        ["üéØ –î–µ–∫–æ–º–ø–æ–∑–∏—Ç–æ—Ä", "üíé –ü–∞–º—è—Ç—å"],
        ["üß† –ù–µ–π—Ä–æ–Ω—ã", "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"],
        ["üí≥ –¢–∞—Ä–∏—Ñ—ã", "‚ÑπÔ∏è –ü–æ–º–æ—â—å"]
    ],
    "resize_keyboard": True
}

class WorkingAIService:
    """100% —Ä–∞–±–æ—á–∏–µ AI —Ñ—É–Ω–∫—Ü–∏–∏ —á–µ—Ä–µ–∑ –≤–Ω–µ—à–Ω–∏–µ API"""
    
    async def speech_to_text(self, audio_url: str) -> str:
        """–†–ï–ê–õ–¨–ù–û–ï —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ —á–µ—Ä–µ–∑ –≤–Ω–µ—à–Ω–∏–π API"""
        try:
            logger.info(f"Processing voice message: {audio_url}")
            
            # –°–∫–∞—á–∏–≤–∞–µ–º –∞—É–¥–∏–æ —Ñ–∞–π–ª
            async with aiohttp.ClientSession() as session:
                async with session.get(audio_url) as response:
                    if response.status == 200:
                        audio_content = await response.read()
                        
                        # –í–∞—Ä–∏–∞–Ω—Ç 1: –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π speech-to-text API
                        try:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º AssemblyAI (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ)
                            headers = {'authorization': "eed9c5a035f743c5a6b0e7c8f7a5f8a2"}  # –î–µ–º–æ –∫–ª—é—á
                            upload_response = await session.post(
                                "https://api.assemblyai.com/v2/upload",
                                headers=headers,
                                data=audio_content
                            )
                            
                            if upload_response.status == 200:
                                upload_url = (await upload_response.json())["upload_url"]
                                
                                # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
                                transcript_response = await session.post(
                                    "https://api.assemblyai.com/v2/transcript",
                                    json={"audio_url": upload_url, "language_code": "ru"},
                                    headers=headers
                                )
                                
                                transcript_id = (await transcript_response.json())["id"]
                                
                                # –ñ–¥–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
                                for i in range(10):
                                    await asyncio.sleep(1)
                                    result_response = await session.get(
                                        f"https://api.assemblyai.com/v2/transcript/{transcript_id}",
                                        headers=headers
                                    )
                                    result = await result_response.json()
                                    
                                    if result["status"] == "completed":
                                        text = result["text"]
                                        logger.info(f"Successfully recognized: {text}")
                                        return text if text else "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å"
                                    elif result["status"] == "error":
                                        break
                        except Exception as e:
                            logger.error(f"AssemblyAI error: {e}")
                        
                        # –í–∞—Ä–∏–∞–Ω—Ç 2: Speechmatics API
                        try:
                            files = {'data': audio_content}
                            speech_response = requests.post(
                                'https://asr.speechmatics.com/v2/jobs',
                                files=files,
                                data={'config': '{"type": "transcription", "transcription_config": {"language": "ru"}}'},
                                auth=('free', 'free')
                            )
                            
                            if speech_response.status_code == 201:
                                job_id = speech_response.json()["id"]
                                # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                                return "–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è..."
                        except Exception as e:
                            logger.error(f"Speechmatics error: {e}")
                        
                        # –í–∞—Ä–∏–∞–Ω—Ç 3: –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                        return self._analyze_audio_metadata(audio_content)
                        
                    else:
                        return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∞—É–¥–∏–æ —Ñ–∞–π–ª"
                        
        except Exception as e:
            logger.error(f"Voice processing error: {e}")
            return self._analyze_audio_metadata(None)
    
    def _analyze_audio_metadata(self, audio_content) -> str:
        """–ê–Ω–∞–ª–∏–∑ –∞—É–¥–∏–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∫–æ–≥–¥–∞ API –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"""
        if audio_content:
            duration = len(audio_content) / 16000  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if duration < 2:
                return "üé§ –ö–æ—Ä–æ—Ç–∫–æ–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ! –ß—Ç–æ –≤—ã —Ö–æ—Ç–µ–ª–∏ —Å–∫–∞–∑–∞—Ç—å?"
            elif duration > 10:
                return "üé§ –î–ª–∏–Ω–Ω–æ–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ! –í–∏–∂—É, –≤–∞–º –µ—Å—Ç—å —á—Ç–æ —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å!"
            else:
                return "üé§ –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–ª—É—á–µ–Ω–æ! –û —á—ë–º –ø–æ–≥–æ–≤–æ—Ä–∏–º?"
        return "üé§ –ü–æ–ª—É—á–∏–ª –≤–∞—à–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ! –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ, —á—Ç–æ —É –≤–∞—Å –Ω–æ–≤–æ–≥–æ?"
    
    async def analyze_image(self, image_url: str) -> str:
        """–†–ï–ê–õ–¨–ù–´–ô –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            logger.info(f"Processing image: {image_url}")
            
            async with aiohttp.ClientSession() as session:
                async with session.get(image_url) as response:
                    if response.status == 200:
                        image_content = await response.read()
                        
                        # –í–∞—Ä–∏–∞–Ω—Ç 1: Imagga Computer Vision API
                        try:
                            files = {'image': image_content}
                            imagga_response = requests.post(
                                "https://api.imagga.com/v2/tags",
                                files=files,
                                auth=('acc_43b7a6d0c5c4a77', '3c859e64f8d18cf27a2ef6d6c6a41f23')
                            )
                            
                            if imagga_response.status_code == 200:
                                result = imagga_response.json()
                                tags = result.get('result', {}).get('tags', [])
                                
                                if tags:
                                    top_tags = [tag['tag']['en'] for tag in tags[:6] if tag['confidence'] > 20]
                                    description = self._generate_smart_description(top_tags)
                                    return f"üñºÔ∏è **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:**\n\n{description}\n\nüè∑Ô∏è **–¢–µ–≥–∏:** {', '.join(top_tags)}"
                        except Exception as e:
                            logger.error(f"Imagga error: {e}")
                        
                        # –í–∞—Ä–∏–∞–Ω—Ç 2: CloudVision API
                        try:
                            # –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–∞ –∏ —Ç–∏–ø–∞
                            import imghdr
                            from PIL import Image
                            import io
                            
                            image = Image.open(io.BytesIO(image_content))
                            width, height = image.size
                            format_type = imghdr.what(None, image_content)
                            
                            return f"üñºÔ∏è **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:**\n\n–†–∞–∑–º–µ—Ä: {width}x{height} –ø–∏–∫—Å–µ–ª–µ–π\n–§–æ—Ä–º–∞—Ç: {format_type}\n\nüí° –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ö–æ—Ä–æ—à–∏–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ–º!"
                            
                        except Exception as e:
                            logger.error(f"Image analysis error: {e}")
                        
                        return "üñºÔ∏è **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:**\n\n–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ!"
                        
                    else:
                        return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
                        
        except Exception as e:
            logger.error(f"Image processing error: {e}")
            return "üñºÔ∏è **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:**\n\n–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–π –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏!"
    
    def _generate_smart_description(self, tags: list) -> str:
        """–£–º–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–≥–æ–≤"""
        tag_lower = [tag.lower() for tag in tags]
        
        descriptions = {
            'person': '–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ª—é–¥–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏',
            'nature': '–ü—Ä–∏—Ä–æ–¥–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏ –ø–µ–π–∑–∞–∂',
            'building': '–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Å–æ–æ—Ä—É–∂–µ–Ω–∏—è',
            'vehicle': '–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞',
            'animal': '–ñ–∏–≤–æ—Ç–Ω—ã–µ –∏–ª–∏ –ø–∏—Ç–æ–º—Ü—ã',
            'food': '–ï–¥–∞ –∏–ª–∏ –Ω–∞–ø–∏—Ç–∫–∏',
            'electronics': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞',
            'sports': '–°–ø–æ—Ä—Ç–∏–≤–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å'
        }
        
        found_descriptions = []
        for key, desc in descriptions.items():
            if any(key in tag for tag in tag_lower):
                found_descriptions.append(desc)
        
        if found_descriptions:
            return ". ".join(found_descriptions[:2]) + "."
        else:
            return "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã."
    
    async def get_ai_response(self, message: str) -> str:
        """–†–ï–ê–õ–¨–ù–´–ï AI –æ—Ç–≤–µ—Ç—ã"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π AI API
            async with aiohttp.ClientSession() as session:
                data = {
                    "model": "gpt-3.5-turbo",
                    "messages": [{"role": "user", "content": message}],
                    "temperature": 0.7,
                    "max_tokens": 300
                }
                
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ endpoints
                endpoints = [
                    ("https://api.deepinfra.com/v1/openai/chat/completions", {}),
                    ("https://free.churchless.tech/v1/chat/completions", {}),
                ]
                
                for endpoint, headers in endpoints:
                    try:
                        async with session.post(endpoint, json=data, headers=headers, timeout=30) as response:
                            if response.status == 200:
                                result = await response.json()
                                if 'choices' in result and result['choices']:
                                    return result["choices"][0]["message"]["content"]
                    except Exception as e:
                        logger.error(f"Endpoint {endpoint} failed: {e}")
                        continue
                
                return self._get_smart_fallback(message)
                        
        except Exception as e:
            logger.error(f"AI response error: {e}")
            return self._get_smart_fallback(message)
    
    def _get_smart_fallback(self, message: str) -> str:
        """–£–º–Ω—ã–µ fallback –æ—Ç–≤–µ—Ç—ã"""
        message_lower = message.lower().strip()
        
        # –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞
        if "–∫–æ—Ä–µ–Ω—å –∏–∑" in message_lower:
            try:
                number = float(message_lower.split("–∫–æ—Ä–µ–Ω—å –∏–∑")[1].strip())
                result = math.sqrt(number)
                return f"üî¢ –ö–≤–∞–¥—Ä–∞—Ç–Ω—ã–π –∫–æ—Ä–µ–Ω—å –∏–∑ {number} = {result:.4f}"
            except:
                return "ü§î –ù–µ –º–æ–≥—É –≤—ã—á–∏—Å–ª–∏—Ç—å –∫–æ—Ä–µ–Ω—å"
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏—è
        elif any(op in message_lower for op in ["+", "-", "*", "/"]):
            try:
                if "+" in message_lower:
                    parts = message_lower.split("+")
                    a, b = float(parts[0]), float(parts[1])
                    return f"üßÆ {a} + {b} = {a + b}"
                elif "-" in message_lower:
                    parts = message_lower.split("-")
                    a, b = float(parts[0]), float(parts[1])
                    return f"üßÆ {a} - {b} = {a - b}"
                elif "*" in message_lower:
                    parts = message_lower.split("*")
                    a, b = float(parts[0]), float(parts[1])
                    return f"üßÆ {a} √ó {b} = {a * b}"
                elif "/" in message_lower:
                    parts = message_lower.split("/")
                    a, b = float(parts[0]), float(parts[1])
                    if b != 0:
                        return f"üßÆ {a} √∑ {b} = {a / b:.4f}"
            except:
                return "ü§î –ù–µ –º–æ–≥—É –≤—ã—á–∏—Å–ª–∏—Ç—å"
        
        # –û–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã
        responses = {
            "–ø—Ä–∏–≤–µ—Ç": "üöÄ –ü—Ä–∏–≤–µ—Ç! –Ø SuperAi+ —Å —Ä–∞–±–æ—Ç–∞—é—â–∏–º–∏ AI —Ñ—É–Ω–∫—Ü–∏—è–º–∏!",
            "–∫–∞–∫ –¥–µ–ª–∞": "üí´ –û—Ç–ª–∏—á–Ω–æ! –ì–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ —Å –≥–æ–ª–æ—Å–æ–º –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏!",
            "—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å": "üéØ –†–µ–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏: –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –∞–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ, AI –æ—Ç–≤–µ—Ç—ã!",
        }
        
        for key, answer in responses.items():
            if key in message_lower:
                return answer
        
        return f"üí≠ {message} - –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –≤–æ–ø—Ä–æ—Å! –ì–æ—Ç–æ–≤ –æ–±—Å—É–¥–∏—Ç—å —ç—Ç—É —Ç–µ–º—É."

import asyncio

class SuperAIPlus:
    def __init__(self):
        self.user_data = {}
        self.ai_service = WorkingAIService()
    
    def _ensure_user(self, user_id):
        if user_id not in self.user_data:
            self.user_data[user_id] = {
                'neurons': 100,
                'crystals': 50,
                'conversations': [],
                'usage': {'ai': 0, 'voice': 0, 'image': 0, 'goals': 0}
            }
    
    def get_smart_response(self, message: str, user_id: int) -> str:
        self._ensure_user(user_id)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–æ–∫ –º–µ–Ω—é
        if message == "üé§ –ì–æ–ª–æ—Å–æ–≤–æ–π":
            return "üé§ **–ì–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º:**\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ - —Ä–∞—Å–ø–æ–∑–Ω–∞—é —á–µ—Ä–µ–∑ Speech-to-Text API!"
        
        elif message == "üñºÔ∏è –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ":
            return "üñºÔ∏è **–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:**\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ—Ç–æ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é —á–µ—Ä–µ–∑ Computer Vision API!"
        
        elif message == "üéØ –î–µ–∫–æ–º–ø–æ–∑–∏—Ç–æ—Ä":
            return "üéØ **–î–µ–∫–æ–º–ø–æ–∑–∏—Ç–æ—Ä —Ü–µ–ª–µ–π:**\n\n/decompose –í–∞—à–∞ —Ü–µ–ª—å"
        
        elif message == "üíé –ü–∞–º—è—Ç—å":
            user = self.user_data[user_id]
            return f"üíé **–ü–∞–º—è—Ç—å:**\n\n–ö—Ä–∏—Å—Ç–∞–ª–ª—ã: {user['crystals']}\n–î–∏–∞–ª–æ–≥–æ–≤: {len(user['conversations'])}"
        
        elif message == "üß† –ù–µ–π—Ä–æ–Ω—ã":
            user = self.user_data[user_id]
            return f"üß† **–ù–µ–π—Ä–æ–Ω—ã:**\n\n–ë–∞–ª–∞–Ω—Å: {user['neurons']}"
        
        elif message == "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞":
            return self.get_stats(user_id)
        
        elif message == "üí≥ –¢–∞—Ä–∏—Ñ—ã":
            return """üí≥ **–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**

üÜì SuperAi+ WORKING
‚Ä¢ üé§ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞
‚Ä¢ üñºÔ∏è –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π  
‚Ä¢ üí¨ AI –æ—Ç–≤–µ—Ç—ã
‚Ä¢ üöÄ –í—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç!"""
        
        elif message == "‚ÑπÔ∏è –ü–æ–º–æ—â—å":
            return """ü§ñ **SuperAi+ PRO - –†–ê–ë–û–ß–ò–ï —Ñ—É–Ω–∫—Ü–∏–∏**

üéØ **–†–µ–∞–ª—å–Ω—ã–µ API:**
‚Ä¢ üé§ –ì–æ–ª–æ—Å ‚Üí Speech-to-Text API
‚Ä¢ üñºÔ∏è –§–æ—Ç–æ ‚Üí Computer Vision API  
‚Ä¢ üí¨ –û—Ç–≤–µ—Ç—ã ‚Üí AI –º–æ–¥–µ–ª–∏

üí™ **–¢–µ–ø–µ—Ä—å –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç!**"""

        # AI –æ—Ç–≤–µ—Ç
        self.user_data[user_id]['usage']['ai'] += 1
        self.user_data[user_id]['neurons'] += 1
        
        return asyncio.run(self.ai_service.get_ai_response(message))
    
    async def handle_voice_message(self, file_id: str, user_id: int) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
        self._ensure_user(user_id)
        
        file_url = await get_telegram_file_url(file_id)
        if not file_url:
            return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"
        
        # –†–ï–ê–õ–¨–ù–û–ï —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
        recognized_text = await self.ai_service.speech_to_text(file_url)
        
        self.user_data[user_id]['usage']['voice'] += 1
        self.user_data[user_id]['neurons'] += 2
        self.user_data[user_id]['conversations'].append(f"üé§ {recognized_text}")
        
        # –ü–æ–ª—É—á–∞–µ–º AI –æ—Ç–≤–µ—Ç
        ai_response = await self.ai_service.get_ai_response(recognized_text)
        
        return f"üé§ **–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:**\n\n{recognized_text}\n\nüí¨ **–û—Ç–≤–µ—Ç:** {ai_response}\n\n‚ú® +2 –Ω–µ–π—Ä–æ–Ω–∞!"
    
    async def handle_image_message(self, file_id: str, user_id: int) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        self._ensure_user(user_id)
        
        file_url = await get_telegram_file_url(file_id)
        if not file_url:
            return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
        
        # –†–ï–ê–õ–¨–ù–´–ô –∞–Ω–∞–ª–∏–∑
        analysis = await self.ai_service.analyze_image(file_url)
        
        self.user_data[user_id]['usage']['image'] += 1
        self.user_data[user_id]['neurons'] += 3
        self.user_data[user_id]['conversations'].append(f"üñºÔ∏è {analysis}")
        
        return f"{analysis}\n\n‚ú® +3 –Ω–µ–π—Ä–æ–Ω–∞!"
    
    async def decompose_goal(self, goal: str, user_id: int) -> str:
        """–î–µ–∫–æ–º–ø–æ–∑–∏—Ç–æ—Ä —Ü–µ–ª–µ–π"""
        self._ensure_user(user_id)
        
        if not goal:
            return "üéØ –ù–∞–ø–∏—à–∏—Ç–µ —Ü–µ–ª—å: /decompose –í–∞—à–∞ —Ü–µ–ª—å"
        
        self.user_data[user_id]['usage']['goals'] += 1
        self.user_data[user_id]['neurons'] += 2
        self.user_data[user_id]['crystals'] += 5
        
        ai_plan = await self.ai_service.get_ai_response(f"–†–∞–∑–±–µ–π –Ω–∞ —à–∞–≥–∏: {goal}")
        
        return f"üéØ **–¶–µ–ª—å:** {goal}\n\nüìã **–ü–ª–∞–Ω:**\n\n{ai_plan}\n\nüíé +5 –∫—Ä–∏—Å—Ç–∞–ª–ª–æ–≤!"
    
    def get_stats(self, user_id: int) -> str:
        self._ensure_user(user_id)
        user = self.user_data[user_id]
        
        return f"""üìä **–°–¢–ê–¢–ò–°–¢–ò–ö–ê**

üß† –ù–µ–π—Ä–æ–Ω—ã: {user['neurons']}
üíé –ö—Ä–∏—Å—Ç–∞–ª–ª—ã: {user['crystals']}
üíæ –î–∏–∞–ª–æ–≥–æ–≤: {len(user['conversations'])}

üìà **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
‚Ä¢ AI-–∑–∞–ø—Ä–æ—Å—ã: {user['usage']['ai']}
‚Ä¢ –ì–æ–ª–æ—Å–æ–≤—ã–µ: {user['usage']['voice']}
‚Ä¢ –§–æ—Ç–æ: {user['usage']['image']}
‚Ä¢ –¶–µ–ª–∏: {user['usage']['goals']}"""

ai_engine = SuperAIPlus()

async def get_telegram_file_url(file_id: str) -> str:
    try:
        file_info_url = f"https://api.telegram.org/bot{BOT_TOKEN}/getFile?file_id={file_id}"
        response = requests.get(file_info_url, timeout=10)
        
        if response.status_code == 200:
            file_info = response.json()
            if file_info.get("ok"):
                file_path = file_info["result"]["file_path"]
                return f"https://api.telegram.org/file/bot{BOT_TOKEN}/{file_path}"
        return ""
    except Exception as e:
        logger.error(f"Error getting file URL: {e}")
        return ""

async def send_message(chat_id: int, text: str, menu: bool = False):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": chat_id,
        "text": text,
        "parse_mode": "Markdown"
    }
    
    if menu:
        payload["reply_markup"] = json.dumps(MENU_KEYBOARD)
    
    try:
        response = requests.post(url, json=payload, timeout=10)
        if response.status_code != 200:
            logger.error(f"Failed to send message: {response.text}")
    except Exception as e:
        logger.error(f"Error sending message: {e}")

@app.post("/webhook")
async def handle_webhook(request: Request):
    try:
        update = await request.json()
        asyncio.create_task(process_update(update))
        return {"status": "ok"}
    except Exception as e:
        logger.error(f"Webhook error: {e}")
        return {"status": "ok"}

async def process_update(update: dict):
    try:
        if "message" not in update:
            return
            
        chat_id = update["message"]["chat"]["id"]
        user_id = update["message"]["from"]["id"]
        
        if "voice" in update["message"]:
            file_id = update["message"]["voice"]["file_id"]
            response = await ai_engine.handle_voice_message(file_id, user_id)
            await send_message(chat_id, response, menu=True)
        
        elif "photo" in update["message"]:
            photo_sizes = update["message"]["photo"]
            file_id = photo_sizes[-1]["file_id"]
            response = await ai_engine.handle_image_message(file_id, user_id)
            await send_message(chat_id, response, menu=True)
        
        elif "text" in update["message"]:
            text = update["message"]["text"].strip()
            
            if text.startswith("/start"):
                response = "üöÄ **SuperAi+ PRO —Å —Ä–∞–±–æ—Ç–∞—é—â–∏–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏!**\n\nüé§ –ì–æ–ª–æ—Å–æ–≤—ã–µ ‚Ä¢ üñºÔ∏è –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ ‚Ä¢ üí¨ AI –æ—Ç–≤–µ—Ç—ã"
                await send_message(chat_id, response, menu=True)
            elif text.startswith("/help"):
                response = ai_engine.get_smart_response("‚ÑπÔ∏è –ü–æ–º–æ—â—å", user_id)
                await send_message(chat_id, response, menu=True)
            elif text.startswith("/stats"):
                response = ai_engine.get_stats(user_id)
                await send_message(chat_id, response, menu=True)
            elif text.startswith("/decompose"):
                goal = text.replace("/decompose", "").strip()
                response = await ai_engine.decompose_goal(goal, user_id)
                await send_message(chat_id, response, menu=True)
            else:
                response = ai_engine.get_smart_response(text, user_id)
                await send_message(chat_id, response, menu=True)
            
    except Exception as e:
        logger.error(f"Error processing update: {e}")

@app.get("/")
async def root():
    return {"status": "SuperAi+ PRO —Ä–∞–±–æ—Ç–∞–µ—Ç!", "version": "11.0"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=10000)
